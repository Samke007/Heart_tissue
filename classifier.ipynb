{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar 2\n",
    "\n",
    "\n",
    "## Klasifikator slika tkiva transplantiranog srca\n",
    "\n",
    "U sklopu seminara, cilj je bio kreirati klasifikator slika tkiva transplantiranog srca u 4 klase prema stupnju odbacivanja tkiva: \n",
    "\n",
    "    - 0R - nema naznaka odbacivanja\n",
    "    - 1R - blago odbacivanje\n",
    "    - 2R - umjereno odbacivanje\n",
    "    - 3R - izrazito odbacivanje\n",
    "\n",
    "Također, ovaj klasifikator je samo pokušaj klasifikacije za ovaj problem. Mala količina podataka može biti uzrok potencijalno niske točnosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvo ćemo ispisati imena direktorija u kojima se nalaze ove 4 klase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0R', '1R', '2R', '3R']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budući da je VGG16 treniran na slikama ImageNet skupa podataka, treba transformirati podatke na 224x224 veličinu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {\n",
    "    # Train uses data augmentation - commented part\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        # transforms.RandomResizedCrop(size=256, scale=(0.95, 1.0)),\n",
    "        # transforms.RandomRotation(degrees=15),\n",
    "        # transforms.ColorJitter(),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(size=2560),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=2560),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=2560),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zatim, potrebno je rastaviti skup podataka u skup za učenje (train), skup za provjeru (validation), skup za testiranje (test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 120 120\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "all_data = datasets.ImageFolder(root='dataset')\n",
    "train_data_len = int(len(all_data)*0.8)\n",
    "valid_data_len = int((len(all_data) - train_data_len)/2)\n",
    "test_data_len = int(len(all_data) - train_data_len - valid_data_len)\n",
    "train_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\n",
    "train_data.dataset.transform = image_transforms['train']\n",
    "val_data.dataset.transform = image_transforms['val']\n",
    "test_data.dataset.transform = image_transforms['test']\n",
    "print(len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "trainiter = iter(train_loader)\n",
    "features, labels = next(trainiter)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jakov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jakov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\Jakov/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [02:30<00:00, 3.69MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze early layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon zamrzivanja predtreniranih slojeva mreže, sada je potrebno definirati klasifikatorski sloj koji će biti prilagođen ovom problemu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 4\n",
    "n_inputs = model.classifier[6].in_features\n",
    "# n_inputs will be 4096 for this case\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 256),       # 256 ili 2560 ??\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, n_classes),\n",
    "    nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.4, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=4, bias=True)\n",
       "      (4): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0R'), (1, '1R'), (2, '2R'), (3, '3R')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.class_to_idx = all_data.class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "list(model.idx_to_class.items())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zatim, potrebno je naučiti model na skupu za učenje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "         criterion,\n",
    "         optimizer,\n",
    "         train_loader,\n",
    "         val_loader,\n",
    "         save_location,\n",
    "         early_stop=3,\n",
    "         n_epochs=20,\n",
    "         print_every=2):\n",
    "   \n",
    "#Initializing some variables\n",
    "  valid_loss_min = np.Inf\n",
    "  stop_count = 0\n",
    "  valid_max_acc = 0\n",
    "  history = []\n",
    "  model.epochs = 0\n",
    "  \n",
    "  #Loop starts here\n",
    "  for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    train_acc = 0\n",
    "    valid_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    ii = 0\n",
    "    \n",
    "    for data, label in train_loader:\n",
    "      ii += 1\n",
    "      data, label = data.to(\"cpu\"), label.to(\"cpu\")\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      \n",
    "      loss = criterion(output, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Track train loss by multiplying average loss by number of examples in batch\n",
    "      train_loss += loss.item() * data.size(0)\n",
    "      \n",
    "      # Calculate accuracy by finding max log probability\n",
    "      _, pred = torch.max(output, dim=1) # first output gives the max value in the row(not what we want), second output gives index of the highest val\n",
    "      correct_tensor = pred.eq(label.data.view_as(pred)) # using the index of the predicted outcome above, torch.eq() will check prediction index against label index to see if prediction is correct(returns 1 if correct, 0 if not)\n",
    "      accuracy = torch.mean(correct_tensor.type(torch.FloatTensor)) #tensor must be float to calc average\n",
    "      train_acc += accuracy.item() * data.size(0)\n",
    "      if ii%15 == 0:\n",
    "        print(f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete.')\n",
    "      \n",
    "    model.epochs += 1\n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      \n",
    "      for data, label in val_loader:\n",
    "        data, label = data.to(\"cpu\"), label.to(\"cpu\")\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        valid_loss += loss.item() * data.size(0)\n",
    "        \n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        correct_tensor = pred.eq(label.data.view_as(pred))\n",
    "        accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "        valid_acc += accuracy.item() * data.size(0)\n",
    "        \n",
    "      train_loss = train_loss / len(train_loader.dataset)\n",
    "      valid_loss = valid_loss / len(val_loader.dataset)\n",
    "      \n",
    "      train_acc = train_acc / len(train_loader.dataset)\n",
    "      valid_acc = valid_acc / len(val_loader.dataset)\n",
    "      \n",
    "      history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "      \n",
    "      if (epoch + 1) % print_every == 0:\n",
    "        print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n",
    "        print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n",
    "        \n",
    "      if valid_loss < valid_loss_min:\n",
    "        torch.save(model.state_dict(), save_location)\n",
    "        stop_count = 0\n",
    "        valid_loss_min = valid_loss\n",
    "        valid_best_acc = valid_acc\n",
    "        best_epoch = epoch\n",
    "        \n",
    "      else:\n",
    "        stop_count += 1\n",
    "        \n",
    "        # Below is the case where we handle the early stop case\n",
    "        if stop_count >= early_stop:\n",
    "          print(f'\\nEarly Stopping Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n",
    "          model.load_state_dict(torch.load(save_location))\n",
    "          model.optimizer = optimizer\n",
    "          history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc','valid_acc'])\n",
    "          return model, history\n",
    "        \n",
    "  model.optimizer = optimizer\n",
    "  print(f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n",
    "  \n",
    "  history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "  return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 \tTraining Loss: 0.0151 \tValidation Loss: 0.0009\n",
      "\t\tTraining Accuracy: 99.48%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 1 \tTraining Loss: 0.0124 \tValidation Loss: 0.0010\n",
      "\t\tTraining Accuracy: 99.58%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 2 \tTraining Loss: 0.0093 \tValidation Loss: 0.0008\n",
      "\t\tTraining Accuracy: 99.58%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 0.0062 \tValidation Loss: 0.0006\n",
      "\t\tTraining Accuracy: 99.79%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 4 \tTraining Loss: 0.0110 \tValidation Loss: 0.0008\n",
      "\t\tTraining Accuracy: 99.58%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 0.0071 \tValidation Loss: 0.0005\n",
      "\t\tTraining Accuracy: 99.79%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 6 \tTraining Loss: 0.0082 \tValidation Loss: 0.0006\n",
      "\t\tTraining Accuracy: 99.69%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Epoch: 7 \tTraining Loss: 0.0094 \tValidation Loss: 0.0008\n",
      "\t\tTraining Accuracy: 99.58%\t Validation Accuracy: 100.00%\n",
      "\n",
      "Best epoch: 5 with loss: 0.00 and acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    save_location='./rejection.pt',\n",
    "    early_stop=5,\n",
    "    n_epochs=8,\n",
    "    print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015059</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009295</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  valid_loss  train_acc  valid_acc\n",
       "0    0.015059    0.000908   0.994792        1.0\n",
       "1    0.012386    0.001003   0.995833        1.0\n",
       "2    0.009295    0.000814   0.995833        1.0\n",
       "3    0.006224    0.000582   0.997917        1.0\n",
       "4    0.010974    0.000848   0.995833        1.0\n",
       "5    0.007096    0.000507   0.997917        1.0\n",
       "6    0.008197    0.000558   0.996875        1.0\n",
       "7    0.009362    0.000774   0.995833        1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Može se primijetiti da je točnost izrazito visoka jer je model prethodno treniran na skupu ImageNet koji sadrži milijune slika raspoređenih u 1000 klasa.\n",
    "\n",
    "Sada valja pogledati i točnost na skupu za testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader, criterion):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    for data, label in test_loader:\n",
    "      data, label = data.to(\"cpu\"), label.to(\"cpu\")\n",
    "      \n",
    "      output = model(data)\n",
    "      \n",
    "      _, pred = torch.max(output, dim=1)\n",
    "      correct_tensor = pred.eq(label.data.view_as(pred))\n",
    "      accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "      test_acc += accuracy.item() * data.size(0)\n",
    "      \n",
    "    test_acc = test_acc / len(test_loader.dataset)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has achieved an accuracy of 100.00% on the test dataset\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./rejection.pt'))\n",
    "test_acc = accuracy(model.to(\"cpu\"), test_loader, criterion)\n",
    "print(f'The model has achieved an accuracy of {100 * test_acc:.2f}% on the test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion):\n",
    "  \n",
    "  classes = []\n",
    "  acc_results = np.zeros(len(test_loader.dataset))\n",
    "  i = 0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "      data, labels = data.to(\"cpu\"), labels.to(\"cpu\")\n",
    "      output = model(data)\n",
    "      \n",
    "      for pred, true in zip(output, labels):\n",
    "        _, pred = pred.unsqueeze(0).topk(1)\n",
    "        correct = pred.eq(true.unsqueeze(0))\n",
    "        acc_results[i] = correct.cpu()\n",
    "        classes.append(model.idx_to_class[true.item()])\n",
    "        i+=1\n",
    "  \n",
    "  results = pd.DataFrame({\n",
    "      'class': classes,\n",
    "      'results': acc_results    \n",
    "  })\n",
    "  results = results.groupby(classes).mean()\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0R</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1R</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2R</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3R</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    results\n",
       "0R      1.0\n",
       "1R      1.0\n",
       "2R      1.0\n",
       "3R      1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_loader, criterion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na temelju rezultata, možemo zaključiti da se model prenaučio. Razlog tome je mali broj podataka koji nije mogao biti povećan zbog malo memorijskog prostora na računalu.\n",
    "\n",
    "Međutim, ovo pokazuje da predtrenirani model poput VGG16 ima izrazitog potencijala za rješavanje ovakvog tipa problema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
